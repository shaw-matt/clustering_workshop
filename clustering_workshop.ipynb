{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96670fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to generate embeddings for a given text\n",
    "# def generate_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#     openai.api_key = api_key\n",
    "#     return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "# # Function to process a single row and generate embeddings for both columns\n",
    "# def process_row(row):\n",
    "#     print(row)\n",
    "#     return generate_embedding(row)\n",
    "\n",
    "# # Create a DataFrame (you can load your own data using pd.read_csv or another method)\n",
    "# df = pd.read_csv('aita.csv')\n",
    "\n",
    "# # Extract the results and add them as new columns to the DataFrame\n",
    "# df[\"title_embedding\"] = df[\"title\"].apply(process_row).apply(literal_eval)\n",
    "\n",
    "# print(\"Finished title embeddings.\")\n",
    "\n",
    "# print(\"Done\")\n",
    "\n",
    "df = pd.read_pickle(\"data/post_data.pkl\")[[\"title\", \"title_embedding\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"title_embedding\"].to_list())\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# distortions = []\n",
    "# inertias = []\n",
    "\n",
    "# K = range(1, 100)\n",
    "\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(15,8))\n",
    "\n",
    "# for i in K:    \n",
    "#     km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42).fit(X)\n",
    "    \n",
    "#     inertias.append(km.inertia_)\n",
    "\n",
    "inertias_df = pd.read_pickle('data/inertias.pkl')\n",
    "\n",
    "inertias_df[\"1d\"] = inertias_df[\"inertias\"].diff()\n",
    "inertias_df[\"2d\"] = inertias_df[\"1d\"].diff()\n",
    "inertias_df[\"3d\"] = inertias_df[\"2d\"].diff()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 6))\n",
    "axes[0, 0].plot(inertias_df.index, inertias_df[\"inertias\"])\n",
    "axes[0, 1].plot(inertias_df.index, inertias_df[\"1d\"], color='orange')\n",
    "axes[1, 0].plot(inertias_df.index, inertias_df[\"2d\"], color='green')\n",
    "axes[1, 1].plot(inertias_df.index, inertias_df[\"3d\"], color='red')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Num clusters')\n",
    "    ax.legend()\n",
    "\n",
    "axes[0, 0].set_title('Raw inertias')\n",
    "axes[0, 1].set_title('1d')\n",
    "axes[1, 0].set_title('2d')\n",
    "axes[1, 1].set_title('3d')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=20, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "km.fit(X)\n",
    "df[\"cluster\"] = km.labels_\n",
    "df[[\"title\", \"cluster\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a798eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = []\n",
    "\n",
    "for i, distances in enumerate(km.transform(X)):\n",
    "    sample_cluster = df[\"cluster\"].iloc[i]\n",
    "    distance_to_cluster = distances[sample_cluster]\n",
    "    distance.append(distance_to_cluster)\n",
    "    \n",
    "df[\"distance\"] = distance\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set your API key\n",
    "# api_key = <key>\n",
    "# openai.api_key = api_key\n",
    "\n",
    "# reasons = []\n",
    "\n",
    "# for k in range(0, 19):\n",
    "#     posts = df.loc[df[\"cluster\"] == k].sort_values(by=\"distance\")[\"title\"].values\n",
    "        \n",
    "#     question = f\"I ran a clustering algorithm on embeddings of post titles on a subreddit called 'r/AmItheAsshole'. \\\n",
    "#         I'd like you to read through as many of these post titles as you can and sum up \\\n",
    "#         exactly ONE main reason why post submitters in this cluster are assholes. \\\n",
    "#         Please be as specific as possible, trying to avoid broad themes like selfishness and lack of empathy etc \\\n",
    "#         and instead opt for specific reasons like 'these people messed up weddings'. \\\n",
    "#         Avoid listing specific posts and commenting on the specific posts. \\\n",
    "#         As far as tone goes, please be as humorous and crass as possible. \\\n",
    "#         Here are the posts for cluster {k}: {posts[0:50]}\"\n",
    "    \n",
    "#     try:\n",
    "#         # Call the OpenAI API\n",
    "#         response = openai.ChatCompletion.create(\n",
    "#             model=\"gpt-3.5-turbo\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"user\", \"content\": question},\n",
    "#             ]\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "#     # Extract and print the answer from the API response\n",
    "#     answer = response.choices[0][\"message\"][\"content\"]\n",
    "#     reasons.append(answer)\n",
    "    \n",
    "# with open('responses.pkl', 'wb') as f:\n",
    "#         pickle.dump(reasons, f)\n",
    "        \n",
    "with open('data/responses.pkl', 'rb') as f:\n",
    "        responses = pickle.load(f)\n",
    "        \n",
    "for i, reason in enumerate(responses):\n",
    "    display(Markdown(\"\\n---\\n\" + reason))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba392d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
